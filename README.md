# Analytics Engineering - NBA Data Pipeline

Projeto de analytics engineering para transformaÃ§Ã£o e modelagem de dados da NBA usando dbt (data build tool) e BigQuery, com deploy automatizado no Google Cloud Run.

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um pipeline de dados completo para anÃ¡lise de estatÃ­sticas da NBA, incluindo:
- TransformaÃ§Ã£o de dados brutos em modelos analÃ­ticos
- DimensÃµes e fatos para anÃ¡lise de apostas esportivas
- Processamento de estatÃ­sticas de jogadores, times e jogos
- AnÃ¡lise de lesÃµes e impactos em performance
- Deploy automatizado no Cloud Run para execuÃ§Ã£o agendada

## ğŸ—ï¸ Arquitetura

```
Raw Data (GCS) â†’ Staging (Views) â†’ Intermediate (Views) â†’ Marts (Tables)
```

- **Staging**: Limpeza e padronizaÃ§Ã£o dos dados brutos
- **Intermediate**: TransformaÃ§Ãµes intermediÃ¡rias e lÃ³gica de negÃ³cio
- **Marts**: Modelos finais para consumo (dimensÃµes e fatos)

## ğŸ“ Estrutura do Projeto

```
analytics-engineering/
â”œâ”€â”€ dbt_nba/                    # Projeto dbt
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/           # Modelos de staging (views)
â”‚   â”‚   â”œâ”€â”€ intermediate/      # Modelos intermediÃ¡rios (views)
â”‚   â”‚   â””â”€â”€ marts/             # Modelos finais (tables)
â”‚   â”œâ”€â”€ dbt_project.yml        # ConfiguraÃ§Ã£o do projeto dbt
â”‚   â””â”€â”€ packages.yml           # DependÃªncias do dbt
â”œâ”€â”€ profiles.yml                # ConfiguraÃ§Ã£o de conexÃ£o BigQuery
â”œâ”€â”€ Dockerfile                  # Imagem Docker para Cloud Run
â”œâ”€â”€ build-and-push.sh          # Script de build e deploy
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â””â”€â”€ README.md                   # Esta documentaÃ§Ã£o
```

## ğŸš€ ConfiguraÃ§Ã£o Local

### PrÃ©-requisitos

- Python 3.13+
- dbt-core e dbt-bigquery instalados
- Acesso ao projeto GCP `smartbetting-dados`
- AutenticaÃ§Ã£o gcloud configurada (`gcloud auth application-default login`)

### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio** (se aplicÃ¡vel)

2. **Instale as dependÃªncias Python:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure o dbt para usar o profiles.yml da raiz:**
   ```bash
   export DBT_PROFILES_DIR=$(pwd)
   ```

   Ou adicione ao seu `~/.zshrc` ou `~/.bashrc`:
   ```bash
   export DBT_PROFILES_DIR=/caminho/absoluto/para/analytics-engineering
   ```

4. **Instale as dependÃªncias do dbt:**
   ```bash
   cd dbt_nba
   dbt deps
   ```

### Executando Localmente

```bash
# Navegar para o diretÃ³rio do projeto dbt
cd dbt_nba

# Verificar conexÃ£o
dbt debug

# Executar todos os modelos
dbt run

# Executar modelos especÃ­ficos
dbt run --select staging.*
dbt run --select marts.*

# Executar testes
dbt test

# Gerar documentaÃ§Ã£o
dbt docs generate
dbt docs serve
```

## â˜ï¸ Deploy no Cloud Run

### PrÃ©-requisitos

- Google Cloud SDK instalado e configurado
- PermissÃµes para criar Cloud Run Jobs
- Artifact Registry configurado
- Service Account com permissÃµes adequadas

### PermissÃµes do Service Account

O service account usado no Cloud Run Job precisa das seguintes roles:

- `roles/bigquery.dataEditor` - Criar/atualizar tabelas e views
- `roles/bigquery.jobUser` - Executar queries no BigQuery
- `roles/bigquery.dataViewer` - Ler dados das tabelas fonte

**Ou use a role mais completa:**
- `roles/bigquery.user` - Inclui todas as permissÃµes acima

### Build e Push da Imagem Docker

1. **Configure as variÃ¡veis de ambiente (opcional):**
   ```bash
   export GCP_PROJECT_ID=smartbetting-dados
   export GCP_REGION=us-east1
   export ARTIFACT_REGISTRY_REPO=dbt-nba-repo
   export IMAGE_NAME=dbt-nba
   export IMAGE_TAG=latest
   ```

2. **Execute o script de build e push:**
   ```bash
   chmod +x build-and-push.sh
   ./build-and-push.sh
   ```

   O script irÃ¡:
   - Configurar autenticaÃ§Ã£o Docker com gcloud
   - Criar builder buildx para multiplataforma
   - Fazer build da imagem para `linux/amd64` (requerido pelo Cloud Run)
   - Fazer push para o Artifact Registry

### ConfiguraÃ§Ã£o do Cloud Run Job

1. **Crie um Cloud Run Job** apontando para a imagem:
   ```
   us-east1-docker.pkg.dev/smartbetting-dados/dbt-nba-repo/dbt-nba:latest
   ```

2. **Configure o Service Account:**
   - Use um service account com as permissÃµes BigQuery mencionadas acima
   - Configure no Cloud Run Job: `--service-account=SERVICE_ACCOUNT_EMAIL`

3. **Configure o comando (opcional):**
   - O comando padrÃ£o Ã©: `dbt run --target prod`
   - VocÃª pode sobrescrever no Cloud Run Job para executar comandos especÃ­ficos

4. **Agende a execuÃ§Ã£o (opcional):**
   - Use Cloud Scheduler para executar o job periodicamente

## ğŸ“Š Modelos de Dados

### Staging (`staging/`)

Modelos que fazem limpeza e padronizaÃ§Ã£o dos dados brutos:

- `stg_active_players` - Jogadores ativos da NBA
- `stg_games` - InformaÃ§Ãµes dos jogos
- `stg_game_player_stats` - EstatÃ­sticas individuais dos jogadores por jogo
- `stg_player_injuries` - InformaÃ§Ãµes de lesÃµes
- `stg_player_props` - Props de apostas dos jogadores
- `stg_season_averages_general_base` - MÃ©dias gerais da temporada
- `stg_season_averages_general_advanced` - EstatÃ­sticas avanÃ§adas
- `stg_season_averages_shooting_by_zone` - EstatÃ­sticas de arremesso por zona
- `stg_team_standings` - ClassificaÃ§Ã£o dos times

### Intermediate (`intermediate/`)

TransformaÃ§Ãµes intermediÃ¡rias e lÃ³gica de negÃ³cio:

- `int_game_player_stats_pilled` - EstatÃ­sticas de jogos em formato longo
- `int_game_player_stats_not_played` - Jogos onde o jogador nÃ£o participou
- `int_game_player_stats_last_game_text` - Texto descritivo do Ãºltimo jogo
- `int_games_teams_pilled` - Dados de jogos por perspectiva do time
- `int_season_averages_general_base` - AgregaÃ§Ãµes de mÃ©dias da temporada

### Marts (`marts/`)

Modelos finais para consumo analÃ­tico:

#### DimensÃµes

- `dim_players` - DimensÃ£o completa de jogadores (com lesÃµes e Ãºltimo jogo)
- `dim_stat_player` - DimensÃ£o de estatÃ­sticas de jogadores (com ratings e anÃ¡lise de backup)
- `dim_teams` - DimensÃ£o de times (com standings e prÃ³ximos jogos)
- `dim_player_shooting_by_zones` - EstatÃ­sticas de arremesso por zona

#### Fatos

- `ft_games` - Fato de jogos
- `ft_game_player_stats` - Fato de estatÃ­sticas de jogadores por jogo

## ğŸ”§ ConfiguraÃ§Ã£o

### Profiles.yml

O arquivo `profiles.yml` na raiz do projeto contÃ©m as configuraÃ§Ãµes de conexÃ£o:

- **dev**: Ambiente de desenvolvimento (usa OAuth local)
- **prod**: Ambiente de produÃ§Ã£o (usa OAuth via Application Default Credentials no Cloud Run)

### VariÃ¡veis de Ambiente

O projeto nÃ£o requer variÃ¡veis de ambiente, pois os valores estÃ£o configurados diretamente no `profiles.yml`. Para desenvolvimento local, certifique-se de ter autenticaÃ§Ã£o gcloud configurada.

## ğŸ§ª Testes

Execute os testes do dbt:

```bash
cd dbt_nba
dbt test
```

Os testes incluem:
- ValidaÃ§Ã£o de unicidade
- ValidaÃ§Ã£o de nÃ£o-nulos
- Testes customizados definidos nos arquivos `models.yml`

## ğŸ“š DocumentaÃ§Ã£o

Gere e visualize a documentaÃ§Ã£o do projeto:

```bash
cd dbt_nba
dbt docs generate
dbt docs serve
```

Isso abrirÃ¡ a documentaÃ§Ã£o interativa no navegador com:
- Linhagem de dados
- DescriÃ§Ãµes dos modelos
- Testes e validaÃ§Ãµes
- DependÃªncias entre modelos

## ğŸ”„ Workflow de Desenvolvimento

1. **Desenvolvimento Local:**
   - FaÃ§a alteraÃ§Ãµes nos modelos SQL
   - Teste localmente com `dbt run --select <modelo>`
   - Execute testes com `dbt test`

2. **Commit e Push:**
   - Commit suas alteraÃ§Ãµes
   - Push para o repositÃ³rio

3. **Deploy:**
   - Execute `./build-and-push.sh` para build e push da imagem
   - A imagem serÃ¡ atualizada no Artifact Registry
   - O Cloud Run Job usarÃ¡ a nova imagem na prÃ³xima execuÃ§Ã£o

## ğŸ› Troubleshooting

### Erro de autenticaÃ§Ã£o local

```bash
gcloud auth application-default login
```

### dbt nÃ£o encontra o profiles.yml

Certifique-se de ter configurado:
```bash
export DBT_PROFILES_DIR=$(pwd)
```

### Erro de plataforma no Cloud Run

O script `build-and-push.sh` jÃ¡ configura o build para `linux/amd64`. Se ainda houver problemas, verifique se o buildx estÃ¡ configurado corretamente.

### PermissÃµes no BigQuery

Verifique se o service account tem as roles necessÃ¡rias:
- `roles/bigquery.user` (ou as roles especÃ­ficas mencionadas acima)

## ğŸ“ Recursos Adicionais

- [DocumentaÃ§Ã£o dbt](https://docs.getdbt.com/docs/introduction)
- [dbt BigQuery Setup](https://docs.getdbt.com/docs/core/connect-data-platform/bigquery-setup)
- [Cloud Run Jobs](https://cloud.google.com/run/docs/create-jobs)
- [BigQuery IAM Roles](https://cloud.google.com/bigquery/docs/access-control)

## ğŸ“„ LicenÃ§a

[Adicione informaÃ§Ãµes de licenÃ§a se aplicÃ¡vel]

## ğŸ‘¥ Contribuidores

[Adicione informaÃ§Ãµes de contribuidores se aplicÃ¡vel]
